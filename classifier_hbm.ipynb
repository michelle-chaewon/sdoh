{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import csv\n",
    "\n",
    "pd.options.display.float_format = '{:.3f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_anno = pd.read_csv('no_gdpr_preprocessed.csv', engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_anno = pd.read_excel('anno_final.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_preprocess(data):\n",
    "    #remove links\n",
    "    data['text_processed'] = data['text'].replace(r'http\\S+', '', regex=True).replace(r'www\\S+', '', regex=True)\n",
    "    #remove Twitter mentions\n",
    "    data['text_processed'] = data['text_processed'].str.replace('@[A-Za-z0-9]+\\s?', '', regex=True)\n",
    "    #remove punctuations\n",
    "    data['text_processed'] = data['text_processed'].str.replace('[{}]'.format(string.punctuation), '')\n",
    "    #remove RT \n",
    "    data['text_processed'] = data['text_processed'].str.replace(\"RT \", '')\n",
    "    #remove double quotes \n",
    "    data['text_processed'] = data['text_processed'].str.replace('“|”', '')\n",
    "    #lowercase\n",
    "    data['text_processed'] = data['text_processed'].str.lower().str.strip()\n",
    "    #replace new line with space\n",
    "    data['text_processed'] = data['text_processed'].str.replace(\"\\n\", ' ')\n",
    "    #other stuff\n",
    "    data['text_processed'] = data['text_processed'].str.replace(\"rt : \", '')\n",
    "    data['text_processed'] = data['text_processed'].str.replace(\"rt _com: \", '')\n",
    "    data['text_processed'] = data['text_processed'].str.replace(\" via\", \"\")\n",
    "    data['text_processed'] = data['text_processed'].str.replace(\"read more:\", \"\")\n",
    "    data['text_processed'] = data['text_processed'].str.replace(\"learn more :\", \"\")\n",
    "    #replace multiple spaces with single space\n",
    "    data['text_processed'] = data['text_processed'].str.replace(' +', ' ')\n",
    "    #strip spaces\n",
    "    data['text_processed'] = data['text_processed'].str.strip()\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_anno = text_preprocess(df_no_anno)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_anno.text_processed = df_no_anno.text_processed.fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_anno_no_null = df_no_anno[~(df_no_anno.text_processed.isnull())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_anno = df_no_anno_no_null.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pipeline(max_df=1.0, max_features=None):\n",
    "    \"\"\"\n",
    "        Create SciKit Learn pipeline for TF-IDF vectorization.\n",
    "\n",
    "        This also provides access to the `CountVectorizer` via \n",
    "        the dict-like key, 'count' on the returned `Pipeline` instance.\n",
    "\n",
    "        Example:\n",
    "            pipe = get_pipeline()\n",
    "            pipe.fit(X, y)\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    return Pipeline([\n",
    "        ('count', CountVectorizer(max_df=max_df, max_features=max_features, ngram_range=(1,2))),\n",
    "        ('tfidf', TfidfTransformer())\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores(y_actual, y_pred, name):\n",
    "    \"\"\"\n",
    "        Get prediction scores as Pandas Series.\n",
    "    \"\"\"\n",
    "\n",
    "    return pd.Series({n: fn(y_actual, y_pred) for n, fn in [\n",
    "        ('F1', f1_score), \n",
    "        ('Recall', recall_score), \n",
    "        ('Precision', precision_score), \n",
    "        ('Accuracy', accuracy_score)\n",
    "    ]}, name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# classifier: HBM-related "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4795\n",
       "1    1205\n",
       "Name: HBM_related, dtype: int64"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_anno.HBM_related.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balance the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "#balance the dataset\n",
    "min_cls_label = df_anno.HBM_related.value_counts().idxmin()\n",
    "min_cls_length = len(df_anno[df_anno.HBM_related == min_cls_label])\n",
    "\n",
    "df_no = df_anno[df_anno.HBM_related == 0]\n",
    "df_yes = df_anno[df_anno.HBM_related == 1]\n",
    "\n",
    "# binary classes\n",
    "if min_cls_label == 1: \n",
    "    df_no = df_no.sample(min_cls_length)\n",
    "else: \n",
    "    df_yes = df_yes.sample(min_cls_length)\n",
    "\n",
    "# combine balanced classes\n",
    "df_hbm_related = pd.concat([df_no, df_yes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced Class Value Counts:\n",
      "0    1205\n",
      "1    1205\n",
      "Name: HBM_related, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#make sure label values are balanced\n",
    "print(f'Balanced Class Value Counts:\\n{df_hbm_related.HBM_related.value_counts()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Train/Test Splits\n",
    "\n",
    "Indices are retained so original text can be matched with results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train shape: (1928,)\n",
      "X test shape: (482,)\n"
     ]
    }
   ],
   "source": [
    "# Create Splits\n",
    "# `train_test_split` will return a Pandas Series with the corresponding Indices.\n",
    "x = df_hbm_related.text_processed\n",
    "y = df_hbm_related.HBM_related\n",
    "# Stratification is probably unncessary here due to pre-balanced classes, but it won't hurt\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=0.8, random_state=0, stratify=y)\n",
    "\n",
    "# Save indices for accessing original text later on...\n",
    "train_idx = x_train.copy().index.tolist()\n",
    "test_idx = x_test.copy().index.tolist()\n",
    "\n",
    "train_df = df_hbm_related.loc[train_idx]\n",
    "test_df = df_hbm_related.loc[test_idx]\n",
    "\n",
    "# convert to Numpy arrays (removing indices)\n",
    "x_train = x_train.to_numpy()\n",
    "x_test = x_test.to_numpy()\n",
    "\n",
    "y_train = y_train.to_numpy()\n",
    "y_test = y_test.to_numpy()\n",
    "\n",
    "print('X train shape:', x_train.shape)\n",
    "print('X test shape:', x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build and Train CountVectorizer / TF-IDF Transformer Pipeline\n",
    "\n",
    "Using 3000 features/vocabulary terms seemed to work well enough for all models. \\\n",
    "More or less might be better, but hyperparameter tuning is unlikely to improve scores significantly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = get_pipeline(max_features=3000)\n",
    "pipe.fit(x_train)\n",
    "\n",
    "X_train_tfidf = pipe.transform(x_train)\n",
    "X_test_tfidf = pipe.transform(x_test)\n",
    "\n",
    "X_train_count = pipe['count'].transform(x_train)\n",
    "X_test_count = pipe['count'].transform(x_test)\n",
    "\n",
    "vocab_arr = sorted(pipe['count'].vocabulary_.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Performance of Various Models\n",
    "\n",
    "1. Dummy Classifier\n",
    "2. SVM\n",
    "3. Multinomial Naive Bayes\n",
    "4. Random Forest\n",
    "5. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ModelBuilder(model_cls, **kwargs):\n",
    "    \"\"\"\n",
    "        Given a model class and keyword arguments,\n",
    "        this will return a function (`wrapped`).\n",
    "\n",
    "        Upon calling the returned function (`wrapped`),\n",
    "        a new instance of the model class will be created\n",
    "        with arguments in kwargs.\n",
    "\n",
    "        Every call of 'wrapped' will create, fit, and predict a new model instance\n",
    "\n",
    "        Ex:\n",
    "\n",
    "            m = ModelBuilder(DummyClassifier, strategy='stratified', random_state=0)\n",
    "            y_pred, model = m(x_train, y_train, x_test)\n",
    "\n",
    "    \"\"\"\n",
    "    def wrapped(_x_train, _y_train, _x_test):\n",
    "        _model = model_cls(**kwargs)\n",
    "        _model.fit(_x_train, _y_train)\n",
    "        _y_pred = _model.predict(_x_test)\n",
    "\n",
    "        return _y_pred, _model\n",
    "\n",
    "    return wrapped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy Classifier: \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F1</th>\n",
       "      <td>0.491</td>\n",
       "      <td>0.491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.494</td>\n",
       "      <td>0.494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.488</td>\n",
       "      <td>0.488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.488</td>\n",
       "      <td>0.488</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           count  tfidf\n",
       "F1         0.491  0.491\n",
       "Recall     0.494  0.494\n",
       "Precision  0.488  0.488\n",
       "Accuracy   0.488  0.488"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dummy classifier\n",
    "print(\"Dummy Classifier: \\n\")\n",
    "dummy_mb = ModelBuilder(DummyClassifier, strategy='stratified', random_state=0)\n",
    "dummy_y_pred_count, dummy_model_count = dummy_mb(X_train_count, y_train, X_test_count)\n",
    "dummy_y_pred_tfidf, dummy_model_tfidf = dummy_mb(X_train_tfidf, y_train, X_test_tfidf)\n",
    "\n",
    "pd.concat([\n",
    "    get_scores(y_test, dummy_y_pred_count, 'count'), \n",
    "    get_scores(y_test, dummy_y_pred_tfidf, 'tfidf')\n",
    "], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machine Classifier:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F1</th>\n",
       "      <td>0.817</td>\n",
       "      <td>0.819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.788</td>\n",
       "      <td>0.817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.848</td>\n",
       "      <td>0.821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.824</td>\n",
       "      <td>0.820</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           count  tfidf\n",
       "F1         0.817  0.819\n",
       "Recall     0.788  0.817\n",
       "Precision  0.848  0.821\n",
       "Accuracy   0.824  0.820"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SVM\n",
    "print('Support Vector Machine Classifier:')\n",
    "svm_mb = ModelBuilder(svm.SVC)\n",
    "svm_y_pred_count, svm_model_count = svm_mb(X_train_count, y_train, X_test_count)\n",
    "svm_y_pred_tfidf, svm_model_tfidf = svm_mb(X_train_tfidf, y_train, X_test_tfidf)\n",
    "\n",
    "pd.concat([\n",
    "    get_scores(y_test, svm_y_pred_count, 'count'), \n",
    "    get_scores(y_test, svm_y_pred_tfidf, 'tfidf')\n",
    "], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive Bayes:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F1</th>\n",
       "      <td>0.801</td>\n",
       "      <td>0.801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.809</td>\n",
       "      <td>0.826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.793</td>\n",
       "      <td>0.777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.799</td>\n",
       "      <td>0.795</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           count  tfidf\n",
       "F1         0.801  0.801\n",
       "Recall     0.809  0.826\n",
       "Precision  0.793  0.777\n",
       "Accuracy   0.799  0.795"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Naive Bayes\n",
    "print('Multinomial Naive Bayes:')\n",
    "nb_mb = ModelBuilder(MultinomialNB)\n",
    "nb_y_pred_count, nb_model_count = nb_mb(X_train_count, y_train, X_test_count)\n",
    "nb_y_pred_tfidf, nb_model_tfidf = nb_mb(X_train_tfidf, y_train, X_test_tfidf)\n",
    "\n",
    "pd.concat([\n",
    "    get_scores(y_test, nb_y_pred_count, 'count'), \n",
    "    get_scores(y_test, nb_y_pred_tfidf, 'tfidf')\n",
    "], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F1</th>\n",
       "      <td>0.844</td>\n",
       "      <td>0.841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.851</td>\n",
       "      <td>0.834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.837</td>\n",
       "      <td>0.848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.842</td>\n",
       "      <td>0.842</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           count  tfidf\n",
       "F1         0.844  0.841\n",
       "Recall     0.851  0.834\n",
       "Precision  0.837  0.848\n",
       "Accuracy   0.842  0.842"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Random Forest\n",
    "print(\"Random Forest:\")\n",
    "rf_mb = ModelBuilder(RandomForestClassifier)\n",
    "rf_y_pred_count, rf_model_count = rf_mb(X_train_count, y_train, X_test_count)\n",
    "rf_y_pred_tfidf, rf_model_tfidf = rf_mb(X_train_tfidf, y_train, X_test_tfidf)\n",
    "\n",
    "pd.concat([\n",
    "    get_scores(y_test, rf_y_pred_count, 'count'), \n",
    "    get_scores(y_test, rf_y_pred_tfidf, 'tfidf')\n",
    "], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F1</th>\n",
       "      <td>0.796</td>\n",
       "      <td>0.809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.759</td>\n",
       "      <td>0.817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.836</td>\n",
       "      <td>0.801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.805</td>\n",
       "      <td>0.807</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           count  tfidf\n",
       "F1         0.796  0.809\n",
       "Recall     0.759  0.817\n",
       "Precision  0.836  0.801\n",
       "Accuracy   0.805  0.807"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "print(\"Logistic Regression:\")\n",
    "lr_mb = ModelBuilder(LogisticRegression,  max_iter=4000, random_state=0)\n",
    "lr_y_pred_count, lr_model_count = lr_mb(X_train_count, y_train, X_test_count)\n",
    "lr_y_pred_tfidf, lr_model_tfidf = lr_mb(X_train_tfidf, y_train, X_test_tfidf)\n",
    "\n",
    "pd.concat([\n",
    "    get_scores(y_test, lr_y_pred_count, 'count'), \n",
    "    get_scores(y_test, lr_y_pred_tfidf, 'tfidf')\n",
    "], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lg:\n",
      "\n",
      "0.7956521739130434\n",
      "0.7593360995850622\n",
      "0.8356164383561644\n",
      "0.8049792531120332\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "model_lg = LogisticRegression(max_iter=4000, random_state=0)\n",
    "model_lg.fit(X_train_count, y_train)\n",
    "pred_lg = model_lg.predict(X_test_count)\n",
    "\n",
    "print(\"lg:\\n\")\n",
    "print(f1_score(y_test, pred_lg))\n",
    "print(recall_score(y_test, pred_lg))\n",
    "print(precision_score(y_test, pred_lg))\n",
    "print(accuracy_score(y_test, pred_lg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "#annotate tweets with no anno\n",
    "texts = list(df_no_anno.text_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test_tfidf = pipe.transform(x_test)\n",
    "# X_train_count = pipe['count'].transform(x_train)\n",
    "\n",
    "texts_count = pipe['count'].transform(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_vec = model_lg.predict(texts_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_anno['HBM_related'] = pred_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hbm_only = df_no_anno[df_no_anno.HBM_related == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hbm_only.to_csv(r'hbm_only.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
